\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2018

% ready for submission
% \usepackage{neurips_2018}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2018}

% to compile a camera-ready version, add the [final] option, e.g.:
\usepackage[final, nonatbib]{nips_2018}

% to avoid loading the natbib package, add option nonatbib:
%     \usepackage[nonatbib]{neurips_2018}

\usepackage[utf8]{inputenc} % allow utf-8 input
%\usepackage[cp1251]{inputenc}
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage[main=russian, english]{babel}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsfonts,amsmath,amssymb}
\usepackage{subcaption}
\usepackage{algorithmicx,algpseudocode,algorithm}
\usepackage{wrapfig,tikz}
\usepackage{amsmath,longtable,fancyhdr,booktabs,multirow,graphicx,float}
\usepackage{adjustbox, bigstrut, tabularx, multirow, makecell, diagbox}
\usepackage{amssymb,xcolor,amsthm}
\usepackage{color}
\usepackage{colortbl}
\usepackage{theoremref}
\usepackage{stmaryrd}
\usepackage{url}            %
\usepackage{booktabs}       %
\usepackage{amsfonts}       %
\usepackage{nicefrac}       %
\usepackage{microtype}      %
\usepackage{caption}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{booktabs} %
\usepackage{enumitem} 
\usepackage{bm}
\usepackage{placeins}
%\usepackage{natbib}

\newcommand{\abs}[1]{\lvert#1\rvert}
\newcommand{\T}{\intercal}
\newcommand{\mbf}[1]{\mathbf{#1}}
\newcommand{\bs}[1]{\boldsymbol{#1}}
\newcommand{\mbb}[1]{\mathbb{#1}}

\newcommand{\ud}{\mathrm{d}}
\newcommand{\up}{\mathrm}
\def\dbar{\mathrm{\mathchar'26\mkern-12mu d}}
\newcommand{\wave}{\sim}
\newcommand{\mcal}{\mathcal}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newtheorem{problem}{Problem}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{remark}{Remark}
\newtheorem{observation}{Observation}
\newtheorem{proposition}{Proposition}
\newtheorem{assumption}{Assumption}
\newtheorem{assumptions}{Assumptions}
\newtheorem{definition}{Definition}
\newtheorem{innercustomthm}{Theorem}
\newenvironment{customthm}[1]
{\renewcommand\theinnercustomthm{#1}\innercustomthm}
{\endinnercustomthm}
\newtheorem{innercustomlem}{Lemma}
\newenvironment{customlem}[1]
{\renewcommand\theinnercustomlem{#1}\innercustomlem}
{\endinnercustomlem}
\newtheorem{innercustomhyp}{Hypothesis}
\newenvironment{customhyp}[1]
{\renewcommand\theinnercustomhyp{#1}\innercustomhyp}
{\endinnercustomhyp}
\newtheorem{innercustomprop}{Proposition}
\newenvironment{customprop}[1]
{\renewcommand\theinnercustomprop{#1}\innercustomprop}
{\endinnercustomprop}
\newtheorem{innercustomass}{Assumption}
\newenvironment{customass}[1]
{\renewcommand\theinnercustomass{#1}\innercustomass}
{\endinnercustomass}

\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}

\definecolor{Gray}{gray}{0.85}
\definecolor{LightCyan}{rgb}{0.88,1,1}

\newcolumntype{a}{>{\columncolor{Gray}}c}
\newcolumntype{b}{>{\columncolor{white}}c}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argsup}{arg\,sup}
\DeclareMathOperator*{\arginf}{arg\,inf}

\makeatletter
\usepackage{xspace}
\def\@onedot{\ifx\@let@token.\else.\null\fi\xspace}
\DeclareRobustCommand\onedot{\futurelet\@let@token\@onedot}

\newcommand{\eqnref}[1]{Eq\onedot~\eqref{#1}}
\newcommand{\figref}[1]{Fig\onedot~\ref{#1}}
\newcommand{\algoref}[1]{Alg\onedot~\ref{#1}}
\newcommand{\equref}[1]{Eq\onedot~\eqref{#1}}
\newcommand{\secref}[1]{Section~\ref{#1}}
\newcommand{\tabref}[1]{Tab\onedot~\ref{#1}}
\newcommand{\thmref}[1]{Theorem~\ref{#1}}
\newcommand{\prgref}[1]{Program~\ref{#1}}
\newcommand{\appref}[1]{Appendix~\ref{#1}}
\newcommand{\clmref}[1]{Claim~\ref{#1}}
\newcommand{\corref}[1]{Corollary~\ref{#1}}
\newcommand{\lemref}[1]{Lemma~\ref{#1}}
\newcommand{\propref}[1]{Proposition~\ref{#1}}
\newcommand{\ptyref}[1]{Property~\ref{#1}}
\newcommand{\assref}[1]{Assumption~\ref{#1}}
\newcommand{\bfx}{\mathbf{x}}
\newcommand{\bfv}{\mathbf{v}}
\newcommand{\bfz}{\mathbf{z}}
\newcommand{\bfe}{{\bs{\epsilon}}}
\newcommand{\bftheta}{{\boldsymbol{\theta}}}
\newcommand{\bfalpha}{{\boldsymbol{\alpha}}}
\newcommand{\bfphi}{{\boldsymbol{\phi}}}
\newcommand{\bfy}{\mathbf{y}}
\newcommand{\bfs}{\mathbf{s}}
\newcommand{\bfh}{\mathbf{h}}
\def\eg{\emph{e.g}\onedot}
\def\Eg{\emph{E.g}\onedot}
\def\ie{\emph{i.e}\onedot}
\def\Ie{\emph{I.e}\onedot}
\def\cf{\emph{cf}\onedot}
\def\Cf{\emph{Cf}\onedot}
\def\etc{\emph{etc}\onedot}
\def\vs{\emph{vs}\onedot}
\def\wrt{w.r.t\onedot}
\def\dof{d.o.f\onedot}
\def\aka{a.k.a\onedot}
\def\iid{i.i.d\onedot}
\def\as{a.s\onedot}
\def\etal{\emph{et al}\onedot}

\newcommand{\y}[1]{{\color{cyan} [YS: {#1}]}}
\newcommand{\s}[1]{{\color{magenta} [SE: {#1}]}}

\usepackage[textsize=tiny]{todonotes}

\title{Отчет по воспроизведению статьи "Generative Modeling by Estimating Gradients of the Data Distribution"}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  Петр Жижин \\
  Факультет Компьютерных наук\\
  ВШЭ\\
  \texttt{piter.zh@gmail.com} \\
  % examples of more authors
   \and
   Даяна Савостьянова \\
   Факультет Компьютерных наук\\
   ВШЭ\\
   \texttt{dayanamuha@gmail.com} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
  Данная работа включает в себя результаты попытки воспроизведения статьи 
  "Generative Modeling by Estimating Gradients of the Data Distribution". Финальной целью является получение схожих со статьей результатов. На данный момент работа содержит проверку начальных экспериментов статьи.
  
  Работа устроена следующим образом, для начала рассмотрим статью, которая является основой для этой работы, далее рассмотрим нашу реализацию определенных частей статьи, подведем результаты о возможности аопсроизведения каждой из частей.
\end{abstract}


\section{Обзор статьи}

В обозреваемой статье ~\cite{DBLP:journals/corr/abs-1907-05600} предлагается вариант генеративной модели, использующей динамику Ланжевена основанную на оценке градиентов распределения данных с помощью score matching ~\cite{DBLP:journals/corr/abs-1907-05600}. Часто выясняется, что данные лежат в низкоразмерных многообразиях, в таких случаях градиент невозможно определить вне данного многообразия. Поэтому в статье данные возмущаются различным шумом из Гауссовского распределения.

\subsection{Лосс}

Для сэмплирования из распределения данных $p_{data}(x)$ при помощи алгоритма
Ланжевена, необходимо уметь строить оценку на градиент
$s_{\theta}(x) \approx \nabla_x \log p_{data}(x)$.

Если бы у нас была известна плотность, то её аппроксимацию можно было бы
посчитать, прооптимизировав следующий функционал:

\[
\mathbb{E}_{p_{data}(x)} \left[ | s_{\theta}(x) - \nabla_x \log p_{data}(x) |_2^2 \right] \to \min_{\theta}
\]

Однако на практике мы не можем знать плотность распределения, а знаем лишь
только некоторую выборку, которая была сгенерирована по данным.

В статье~\cite{sliced_score_matching} было показано, что эту формулу можно так
же представить и в другом виде, который можно использовать для подсчёта.

Мы будем использовать две переформулировки данного уравнения в разных задачах.
Первая из них называется Sliced Score Matching: 

\begin{equation}
\mathbb{E}_{p_{data}(x)} \mathbb{E}_{p_v} \left[ v^T \nabla_x s_{\theta}(x) v + \frac{1}{2} |s_{\theta}(x)|_2^2 \right]
\label{eq:sliced_score_matching}
\end{equation}

Для подсчёта этой формулы, мы генерируем случайные вектора $v$. Например, это могут быть стандартные
гауссовские вектора.

$\nabla_x s_{\theta}(x)$ --- это гессиан логарифма плотности распределений. Так как напрямую
посчитать гессиан для любой достаточно большой модели было бы практически невозможно, то
он напрямую не считается. В той же статье было показано, как при помощи любой библиотеки автоматического
подсчёта градиента можно посчитать этот лосс, не считая при этом гессиан.

\begin{algorithm}
	\caption{Sliced Score Matching}
	\label{alg:ssm}
	\begin{algorithmic}[1]
		\Require{$\bfs_m(\bfx;\bftheta), \bfx, \bfv$}
		\State{$\bfv^\intercal \nabla_\bfx \bfs_m(\bfx;\bftheta) \gets \texttt{grad}(\bfv^\intercal \bfs_m(\bfx;\bftheta), \bfx)$}
		\State{$J \gets \frac12(\bfv^\intercal \bfs_m(\bfx;\bftheta))^2$ (or $J \gets \frac12\norm{\bfs_m(\bfx;\bftheta)}_2^2$)}
		\State{$J \gets J + \bfv^\intercal \nabla_\bfx \bfs_m(\bfx;\bftheta) \bfv$}
		\item[]
		\Return{$J$}
	\end{algorithmic}
\end{algorithm}

Для данного алгоритма значение $\bfs_m(\bfx;\bftheta)$ получается оценкой градиента нейронной сетью.

Вторая называется Denoising score matching:
\begin{equation}
\mathbb{E}_{q(\tilde{x} | x)p_{data}(x)} \left[ |s_{\theta}(\tilde{x}) - \nabla_x \log q_{\sigma}(\tilde{x} | x)|_2^2 \right]
\label{eq:denoising_score_matching}
\end{equation}

Тут суть в том, чтобы в данные добавлялся шум $q(\tilde{x} | x)$ с известной
плотностью, матожиданием равным $x$ и низкой дисперсией.  За счет привнесения шума с известным распределением DSM требует в 4 раза меньше операций, чем SSM согласно ~\cite{DBLP:journals/corr/abs-1907-05600} .




\section{Эксперимент на смеси гауссовских распределений}

\subsection{Неверная оценка градиента правдоподобия выборки}
Повторим эксперимент из статьи, чтобы показать, что Score Matching лосс адекватно
оценивает градиент только в областях высокой плотности. В качестве модели был
использован MLP (Multi-Layer Perceptron) с тремя слоями. Размером скрытого слоя
128, функция активации Softplus. Данные генерировались из смеси распределений:
\[
\frac{1}{5} \mathcal{N}\left( \left( -5, -5\right), I \right)+\frac{4}{5} \mathcal{N}\left( \left( 5, 5\right), I \right)
\]

В качестве оптимизатора был взят Adam с lr = 0.001 с размером батча 128. 
Модель училась 10000 итераций.

В качестве лосса для Score Matching тут использовался Sliced Score Matching с
генерацией только одного случайного вектора $v$ для каждого элемента выборки.

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=0.95\textwidth]{fig2a}
		\caption{$\nabla_x \log p_{data}(x)$ --- истинный градиент логарифма правдоподобия}
		\label{fig:2a}
	\end{subfigure}
	\begin{subfigure}[b]{0.45\textwidth}
		\centering
		\includegraphics[width=0.95\textwidth]{fig2b}
		\caption{$s_{\theta}(x)$ --- оценка на $\nabla_x \log p_{data}(x)$}
		\label{fig:2b}
	\end{subfigure}
	\caption{Сравнение градиента истинного логарифма правдоподобия с его оценкой
		MLP сетью, красные области соответствуют области с высоким значеием плотности
		рассматриваемого распределения}
	\label{fig:2}
\end{figure}

На Рис.~\ref{fig:2} мы можем видеть, что нейронная сеть адекватно оценивает
градиент $\nabla_x \log p_{data}(x)$ только в области вокруг мод распределения.
Стрелки указывают в то же направление, что и настоящий градиент плотности.

Значения ожидаемо отличаются в области, где плотность мала.

Данный результат полностью сходится с тем, что было получено в статье.

Стоит отметить, что именно поэтому некорректно было бы использовать обычный
алгоритм Ланжевена. Плотность рассматриваемого распределения везде ненулевая.
Рассмотрим это в следующем пункте.




\subsection{Динамика Ланжевена}

Хотим посмотреть на разницу в работе обычного Ланжевена и Ланжевена с отжигом. В алгоритме будем использовать для подсчета честные градиенты. Для этого генерировать данные будем как в предыдущем пункте из смеси Гауссовских распределений. Рис.~\ref{fig:3a} В качестве начальных точек для обеих динамик будем брать равномерно выбранные точки из квадрата $[-8, 8] \times [-8, 8]$.  Для обычного Ланжевена возьмем 1000 шагов, $\varepsilon=0.1$. Рис.~\ref{fig:3b}. Для Ланжевена с отжигом (алгоритм~\ref{alg:anneal}) 100 шагов, $\varepsilon=0.1$. В статье предлагается взять $\sigma_i$ из геометрической прогрессии, где $\sigma_{1} = 10, \sigma_{10} = 0.1$. Отметим, что при данных параметрах предложенный  в статье алгоритм динамики Ланжевена с отжигом не сходится. После некоторых экспериментов с параметрами пришли к следующим параметрам: 
$\sigma_i$ из геометрической прогрессии, где $\sigma_{1} = 20, \sigma_{10} = 0.7$. Рис.~\ref{fig:3c}.

\begin{wrapfigure}[15]{r}{0.5\textwidth}
	\vspace{-2.2em}
	\begin{minipage}{0.5\textwidth}
		\begin{algorithm}[H]
			\caption{Annealed Langevin dynamics.}
			\label{alg:anneal}
			\begin{algorithmic}[1]
				\Require{$\{\sigma_i\}_{i=1}^L, \epsilon, T$.}
				\State{Initialize $\tilde{\bfx}_0$}
				\For{$i \gets 1$ to $L$}
				\State{$\alpha_i \gets \epsilon \cdot \sigma_i^2/\sigma_L^2$} \Comment{$\alpha_i$ is the step size.}
				\For{$t \gets 1$ to $T$}
				\State{Draw $\bfz_t \sim \mcal{N}(0, I)$}
				\State{\resizebox{0.75\textwidth}{!}{$\tilde{\bfx}_{t} \gets \tilde{\bfx}_{t-1} + \dfrac{\alpha_i}{2} \bfs_\bftheta(\tilde{\bfx}_{t-1}, \sigma_i) + \sqrt{\alpha_i}~ \bfz_t$}}
				\EndFor
				\State{$\tilde{\bfx}_0 \gets \tilde{\bfx}_T$}
				\EndFor
				\item[]
				\Return{$\tilde{\bfx}_T$}
			\end{algorithmic}
		\end{algorithm}
	\end{minipage}
\end{wrapfigure}

Заметим, что обычный Ланжевен плохо угадывает доли событий по компонентам смеси. Это случается из-за того, что при взятиии градиента $\log p_{data}$ логарифм веса является константным слагаемым, а значит не участвует в финальном выражении.С другой стороны Ланжевен с отжигом смог уловить соотношение между компонентами, в связи с меняющейся дисперсией шума: более весомая часть смеси более устойчива по мере уменьшения дисперсии шума.


Отметим, что качество работы последнего метода зависят от выбора сигмы. Метод может как не сойтись, так и выдавать результаты в той же мере неверные, как и обычный Ланжевен.




\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{fig3a}
		\caption{Сэмплирование}
		\label{fig:3a}
	\end{subfigure}
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{fig3b}
		\caption{Динамика Ланжевина}
		\label{fig:3b}
	\end{subfigure}
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{fig3c}
		\caption{Динамика Ланжевена с отжига}
		\label{fig:3c}
	\end{subfigure}
\end{figure}

Данный результат в целом сходится с тем, что было получено в статье, но стоит отметить, что параметры в статье указаны неподходящие.

%Правка


\section{Эксперементы на картинках}

\subsection{Модель}

Для оценки градиента правдоподобия данных по картинке используется модель 4-х
каскадного RefineNet~\cite{DBLP:journals/corr/LinMS016} с модификациями.

К RefineNet были применены следующие модификации:
\begin{enumerate}
    \item Для снижения разрешения для создания входов блоков RefineNet
        используется не даунскейлинг, а свёртка с dilation. Для создания
        входа для второго блока RefineNet дополнительно используется average
        пулинг с размером ядра 2 и страйдом 2. Параметр dilation равен 1 для
        входа первого блока RefineNet, для каждого последующего входа dilation
        умножается на 2.
    \item Вместо макс-пулинга в блоке chained residual pooling используется
        average-пулинг.
    \item Для нормализации вместо батч-нормализации используется условная
        инстанс нормализация. Обуславливание необходимо для того, чтобы
        учитывать уровень зашумлённости изображения и более подробно будет
        описано позднее в разделе~\ref{section:condinstancenorm}
    \item Вместо ReLU активаций используется активационная функция ELU со
        стандартными параметрами.
    \item Базовое количество каналов в RefineNet равно 128 для CIFAR и 64 для
        MNIST. В первом блоке RefineNet используется базовое количество
        каналов, в остальных --- удвоенное количество базовых каналов.
\end{enumerate}

\subsection{Обуславливание нейронной сети на параметр $\sigma$}\label{section:condinstancenorm}

Для корректной работы алгоритма Ланжевена с отжигом, необходимо каким-то
образом обуславливать модель на уровень добавляемого в данные шума (в алгоритме
используется оценка $s_{\theta}(x, \sigma)$, которая должна зависеть от
$\sigma$). Для этого мы повторяем тот же метод обуслаливания, который
применялся в статье. Он называется CondInstanceNorm++ и работает следующим
образом:

Пусть $x$ --- это картинка с $C$ каналов. $\mu_k$ --- это среднее значение
яркости пикселя в изображении $x$ для канала $k$. $s_k$ --- это стандартное
отклонение яркости пикселя на канале $k$.  Так же считаются $m$ и $v$ ---
оценки среднего и стандартного $\mu_k$ по всем каналам $k=1\ldots C$.  
Обуславливание на уровень шума происходит таким образом, что для разного
$\sigma_i$ выбираются разные параметры нормализации. Тогда нормализованное
изображение $z_k$ задаётся следующим образом:

\[
z_k = \gamma[i, k] \frac{x_k - \mu_k}{s_k} + \beta[i,k] + \alpha[i,k]\frac{\mu_k - m}{v}
\]

$i$ --- это индекс внедряемого шума.
$\gamma \in \mathbb{R}^{L \times C}$, $\beta \in \mathbb{R}^{L \times C}$, $\alpha \in \mathbb{R}^{L \times C}$

$L$ --- это количество различных шумов, которые мы внедряем в модель при отжиге.

\subsection{Полученные результаты}

Модель обучалась на двух датасетах: MNIST и CIFAR. В качестве лосса для
обучения использовался Denoising Score Matching. Зашумление изображений
проводилось добавкой к изображению нормального распределения с нулевым
матожиданием и стандартным отклонением $\sigma$.

При обучении использовалось 10 уровней шума $\sigma_i$, расположенных
в геометрической прогрессии. $\sigma_1 = 1$, $\sigma_{10} = 0.01$.
При этом уровень шума $0.01$ незаметен человеческому глазу. Для
картинок $3\sigma_{10}$ шума эквивалентно изменению интенсивности
индивидуального пикселя на $7.68$ (если принимать, что интенсивность
находится в диапазоне $[0; 256]$.

\begin{figure}
    \centering
    \includegraphics[width=0.95\textwidth]{dsmloss}
    \caption{DSM лосс на MNIST и CIFAR}\label{fig:dsmloss}
\end{figure}

Модели обучались на одном GPU Tesla V100. MNIST обучался
на протяжении 450 эпох, CIFAR учился 230 эпох.

В изначальной статье использовалось два GPU Tesla V100 при
обучении на CIFAR. Так как мы использовали только один GPU,
то из-за избежания ошибок по переполнению памяти размер
батча на CIFAR был снижен до 100 картинок (вместо 128).
Размер батча на MNIST не менялся и был равен 128.

Так же в изначальной статье модель на CIFAR училась дольше,
там её учили на протяжении около 500 эпох. Так как модель
на CIFAR учится гораздо медленнее, а времени к дедлайну
дообучить модель у нас не хватило, то резульат был зафиксирован
на 230 эпохах вместо 500.

На Рис.~\ref{fig:dsmloss} можно увидеть лосс при обучении
модели на датасетах MNIST и CIFAR-10.

\subsubsection{Результаты генерации на MNIST}

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=0.95\textwidth]{generated_images_mnist8x8}
    \caption{Сгенерированные картинки}\label{fig:mnist8x8sample}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=0.95\textwidth]{generation_process_mnist}
    \caption{Процесс генерации картинки алгоритмом Ланжевена с отжигом}\label{fig:mnist_gen}
    \end{subfigure}
    \caption{Пример генерации картинок на MNIST}
\end{figure}

Для генерации картинок используется динамика Ланжевена с отжигом.
Генерация начинается со случайной картинки, генерируемой из
равномерного шума на отрезке $[0; 1]$.

Learning rate устанавливался равным $5 \cdot 10^{-5}$, количество
шагов динамики для одного значения шума $\sigma_i$ было равно 100.

На Рис.~\ref{fig:mnist8x8sample} можно увидеть пример того, как алгоритм
Ланжевена с отжигом генерирует картинки по модели, обученной на MNIST.
Данный набор картинок является случайным и не был выбран специально, чтобы
показать более качественный результат.

На Рис.~\ref{fig:mnist_gen} можно увидеть процесс генерации картинки. Каждый
столбец соответствует финальному результату алгоритма Ланжевена при
фиксированном уровне шума $\sigma_i$.

Как можно заметить, картинки генерируются достаточно качественные, но не
без ошибок. Иногда можно увидеть кляксы вместо цифр.

\subsubsection{CIFAR-10}

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=0.95\textwidth]{generated_images_cifar8x8}
    \caption{Сгенерированные картинки}\label{fig:cifar8x8sample}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=0.95\textwidth]{generation_process_cifar}
    \caption{Процесс генерации картинки алгоритмом Ланжевена с отжигом}\label{fig:cifar_gen}
    \end{subfigure}
    \caption{Пример генерации картинок на CIFAR}
\end{figure}

Процесс генерации картинок на CIFAR аналогичен тому же процессу для MNIST.
Параметры алгоритма используются одни и те же.

На Рис.~\ref{fig:cifar8x8sample} и~\ref{fig:cifar_gen} можно увидеть
аналогичные результаты на датасете CIFAR.

Как можно заметить, в отличие от MNIST результаты на CIFAR
неудовлетворительные. Изображения получились примерно в одной цветовой гамме.
Вместо чётко различимых объектов на картинках можно различить только какие-то
общие черты.  

Мы предполагаем, что это может быть связано с тем, что модель не дообучилась и
дальнейшее обучение должно улучшить результат.

\begin{figure}
\begin{center}
    \begin{tabular}{|l||c|c|}
        \hline
        Результат & Inception score & FID score \\ 
        \hline
        Исходная статья & $8.87\pm.12$ & 25.32 \\
        \hline
        Наша модель & $4.17\pm.13$ & $110.85$ \\
        \hline
    \end{tabular}
\end{center}
\caption{Численная оценка результата генерации}\label{fig:cifar_scores}
\end{figure}

Для количественной оценки полученных картинок были подсчитаны Inception score и
FID score.  Оценки были подсчитаны на выборке из 5000 случайно сгенерированных
картинок. На Рис.~\ref{fig:cifar_scores} можно увидеть данные оценки и их
сравнение с резульатом, представленным в оригинальной статье. Как можно
заметить, полученный у нас результат гораздо хуже, чем тот, что был представлен
в статье. Это ожидаемо с учётом того, что как было сказано выше, картинки
генерируются не лучшего качества.

\bibliographystyle{unsrt} 
\bibliography{rev} 


\end{document}
